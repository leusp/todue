
@misc{noauthor_pdfdataextractor_nodate,
	title = {{PDFDataExtractor}: {A} {Tool} for {Reading} {Scientific} {Text} and {Interpreting} {Metadata} from the {Typeset} {Literature} in the {Portable} {Document} {Format} {\textbar} {Journal} of {Chemical} {Information} and {Modeling}},
	url = {https://pubs-acs-org.oxy.idm.oclc.org/doi/10.1021/acs.jcim.1c01198?ref=pdf},
	urldate = {2025-12-12},
	file = {PDFDataExtractor\: A Tool for Reading Scientific Text and Interpreting Metadata from the Typeset Literature in the Portable Document Format | Journal of Chemical Information and Modeling:files/1735/acs.jcim.html:text/html},
}

@inproceedings{li_review_2023,
	title = {Review of {Semi}-{Structured} {Document} {Information} {Extraction} {Techniques} {Based} on {Deep} {Learning}},
	url = {https://ieeexplore.ieee.org/document/10339515},
	doi = {10.1109/MLCCIM60412.2023.00022},
	abstract = {With the advent of global digital transformation, using an intelligent method based on deep learning to extract crucial information from semi-structured documents, as represented by various types of receipts and invoices, has emerged as an imperative measure to ensure business stability, data security, and improved work efficiency. This paper provides a detailed review on deep learning-based techniques for information extraction, with systematic introduction, hierarchical analysis, method comparison, and summary with expectations for future development. The review begins with a comprehensive explication of the defining characteristics of semi-structured documents, along with a detailed introduction to the research background, application areas, and technical challenges related to information extraction from semi-structured documents. Then the review extends to an overview of two developmental stages, i.e. the shift from traditional information extraction to deep learning-based information extraction, followed by discussion about technical architecture and method classification, which elaborates on key technologies in terms of typical datasets, detection and recognition, and information reduction. Lastly, paper summarizes the prospects and development in the field. Future research will focus on strengthening algorithm universal and lightweight, as well as improving information protection capabilities and the diversity of datasets.},
	urldate = {2025-12-12},
	booktitle = {2023 2nd {International} {Conference} on {Machine} {Learning}, {Cloud} {Computing} and {Intelligent} {Mining} ({MLCCIM})},
	author = {Li, Yangchun and Jiang, Wei and Song, Shouyou},
	month = jul,
	year = {2023},
	keywords = {Computer architecture, deep learning, Deep learning, detection and recognition, Finance, information extraction, Information retrieval, Medical services, Optical character recognition, semi-structured documents, Systematics},
	pages = {112--119},
	file = {Full Text PDF:files/1737/Li et al. - 2023 - Review of Semi-Structured Document Information Ext.pdf:application/pdf},
}

@article{kovacevic_combining_2013,
	title = {Combining rules and machine learning for extraction of temporal expressions and events from clinical narratives},
	volume = {20},
	issn = {1067-5027},
	url = {https://doi.org/10.1136/amiajnl-2013-001625},
	doi = {10.1136/amiajnl-2013-001625},
	abstract = {Objective Identification of clinical events (eg, problems, tests, treatments) and associated temporal expressions (eg, dates and times) are key tasks in extracting and managing data from electronic health records. As part of the i2b2 2012 Natural Language Processing for Clinical Data challenge, we developed and evaluated a system to automatically extract temporal expressions and events from clinical narratives. The extracted temporal expressions were additionally normalized by assigning type, value, and modifier.Materials and methods The system combines rule-based and machine learning approaches that rely on morphological, lexical, syntactic, semantic, and domain-specific features. Rule-based components were designed to handle the recognition and normalization of temporal expressions, while conditional random fields models were trained for event and temporal recognition.Results The system achieved micro F scores of 90\% for the extraction of temporal expressions and 87\% for clinical event extraction. The normalization component for temporal expressions achieved accuracies of 84.73\% (expression's type), 70.44\% (value), and 82.75\% (modifier).Discussion Compared to the initial agreement between human annotators (87–89\%), the system provided comparable performance for both event and temporal expression mining. While (lenient) identification of such mentions is achievable, finding the exact boundaries proved challenging.Conclusions The system provides a state-of-the-art method that can be used to support automated identification of mentions of clinical events and temporal expressions in narratives either to support the manual review process or as a part of a large-scale processing of electronic health databases.},
	number = {5},
	urldate = {2025-12-12},
	journal = {J Am Med Inform Assoc},
	author = {Kovačević, Aleksandar and Dehghan, Azad and Filannino, Michele and Keane, John A and Nenadic, Goran},
	month = sep,
	year = {2013},
	pages = {859--866},
	file = {Full Text:files/1739/Kovačević et al. - 2013 - Combining rules and machine learning for extractio.pdf:application/pdf},
}

@inproceedings{sekiya_improvements_2022,
	title = {Improvements of a {Hybrid} {Syllabus} {Search} {Tool} by {Syllabus}-related {Heuristics}},
	url = {https://ieeexplore.ieee.org/document/9962619},
	doi = {10.1109/FIE56618.2022.9962619},
	abstract = {This Research Full Paper proposes a new method to collect course syllabi. A syllabus is essential information about a course in a university. Students grasp the topics covered by a course through its syllabus, and faculties understand the curriculum offered by the university by a set of syllabi. Thus, a syllabus helps to analyze educational activities. Our previous work proposed a hybrid method that combines Google API as a general keyword search engine and linear support vector machine (SVM) as content-based classification models. We could find more computer science (CS) syllabus pages than using each method alone by employing the hybrid method. This paper extends the hybrid method for finding a directory page with many links to the syllabus pages. We use the hybrid method to collect candidate directory pages and select the true directory pages from the candidates by the three heuristics: (1) Hyperlink-Induced Topic Search (HITS) score. (2) URL pattern, and (3) Content word. (1) HITS score: The relation between directory pages and syllabus pages resembles the relation between the HITS algorithm’s hubs and authorities. We use hub scores to select directory pages. (2) URL pattern: Pages with similar contents and roles share a part of their URLs. We exploit this observation to select syllabus pages. (3) Content word: We expect a syllabus page to include words of the Body of Knowledge (BOK) ‘Computing Science Curricula CS2013,’ released by the ACM and IEEE Computer Society. We use the words extracted from the CS2013 BOK to measure how each candidate syllabus page is related to CS2013. With these three heuristics, we achieved 32\%, the percentage of CS syllabus pages included on candidate pages.},
	urldate = {2025-12-12},
	booktitle = {2022 {IEEE} {Frontiers} in {Education} {Conference} ({FIE})},
	author = {Sekiya, Takayuki and Matsuda, Yoshitatsu and Yamaguchi, Kazunori},
	month = oct,
	year = {2022},
	note = {ISSN: 2377-634X},
	keywords = {Computer science, Computational modeling, Computer Science Curricula, Feature extraction, Heuristic algorithms, HITS algorithm, Keyword search, Linear SVM, Support vector machines, Syllabus Analysis, Uniform resource locators, Web Crawling},
	pages = {1--8},
	file = {Full Text PDF:files/1741/Sekiya et al. - 2022 - Improvements of a Hybrid Syllabus Search Tool by S.pdf:application/pdf},
}

@article{zhu_pdfdataextractor_2022,
	title = {{PDFDataExtractor}: {A} {Tool} for {Reading} {Scientific} {Text} and {Interpreting} {Metadata} from the {Typeset} {Literature} in the {Portable} {Document} {Format}},
	volume = {62},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1549-9596, 1549-960X},
	shorttitle = {{PDFDataExtractor}},
	url = {https://pubs.acs.org/doi/10.1021/acs.jcim.1c01198},
	doi = {10.1021/acs.jcim.1c01198},
	language = {en},
	number = {7},
	urldate = {2025-12-12},
	journal = {J. Chem. Inf. Model.},
	author = {Zhu, Miao and Cole, Jacqueline M.},
	month = apr,
	year = {2022},
	pages = {1633--1643},
	file = {Full Text PDF:files/1743/Zhu and Cole - 2022 - PDFDataExtractor A Tool for Reading Scientific Te.pdf:application/pdf},
}

@article{zhu_visual_2024,
	title = {A visual analysis approach for data transformation via domain knowledge and intelligent models},
	volume = {30},
	issn = {0942-4962, 1432-1882},
	url = {https://link.springer.com/10.1007/s00530-024-01331-x},
	doi = {10.1007/s00530-024-01331-x},
	language = {en},
	number = {3},
	urldate = {2025-12-12},
	journal = {Multimedia Systems},
	author = {Zhu, Haiyang and Yin, Jun and Chu, Chengcan and Zhu, Minfeng and Wei, Yating and Pan, Jiacheng and Han, Dongming and Tan, Xuwei and Chen, Wei},
	month = jun,
	year = {2024},
	pages = {126},
	file = {Full Text PDF:files/1745/Zhu et al. - 2024 - A visual analysis approach for data transformation.pdf:application/pdf},
}

@article{zhu_pdfdataextractor_2022-1,
	title = {{PDFDataExtractor}: {A} {Tool} for {Reading} {Scientific} {Text} and {Interpreting} {Metadata} from the {Typeset} {Literature} in the {Portable} {Document} {Format}},
	volume = {62},
	issn = {1549-9596},
	url = {https://doi.org/10.1021/acs.jcim.1c01198},
	doi = {10.1021/acs.jcim.1c01198},
	number = {7},
	journal = {J. Chem. Inf. Model.},
	author = {Zhu, Miao and Cole, Jacqueline M.},
	month = apr,
	year = {2022},
	note = {Publisher: American Chemical Society},
	pages = {1633--1643},
	annote = {doi: 10.1021/acs.jcim.1c01198},
}

@article{zhu_visual_2024-1,
	title = {A visual analysis approach for data transformation via domain knowledge and intelligent models},
	volume = {30},
	issn = {0942-4962, 1432-1882},
	url = {https://link.springer.com/10.1007/s00530-024-01331-x},
	doi = {10.1007/s00530-024-01331-x},
	language = {en},
	number = {3},
	urldate = {2025-12-12},
	journal = {Multimedia Systems},
	author = {Zhu, Haiyang and Yin, Jun and Chu, Chengcan and Zhu, Minfeng and Wei, Yating and Pan, Jiacheng and Han, Dongming and Tan, Xuwei and Chen, Wei},
	month = jun,
	year = {2024},
	pages = {126},
	file = {Full Text PDF:files/1749/Zhu et al. - 2024 - A visual analysis approach for data transformation.pdf:application/pdf},
}

@article{budhiraja_supervised_2020,
	title = {A supervised learning approach for heading detection},
	volume = {37},
	copyright = {© 2020 John Wiley \& Sons, Ltd},
	issn = {1468-0394},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.12520},
	doi = {10.1111/exsy.12520},
	abstract = {As the popularity of the portable document format (PDF) file format increases, research that facilitates PDF text analysis or extraction is necessary. Heading detection is a crucial component of PDF-based text classification processes. This research involves training a supervised learning model to detect headings by systematically testing and selecting classifier features using recursive feature elimination. Results indicate that decision tree is the best classifier with an accuracy of 95.83\%, sensitivity of 0.981, and a specificity of 0.946. This research into heading detection contributes to the field of PDF-based text extraction and can be applied to the automation of large scale PDF text analysis in a variety of professional and policy-based contexts.},
	language = {en},
	number = {4},
	urldate = {2025-12-12},
	journal = {Expert Systems},
	author = {Budhiraja, Sahib Singh and Mago, Vijay},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/exsy.12520},
	keywords = {machine learning, heading detection, supervised learning algorithm, text segmentation},
	pages = {e12520},
	file = {Full Text PDF:files/1751/Budhiraja and Mago - 2020 - A supervised learning approach for heading detecti.pdf:application/pdf},
}

@article{liu_class_2025,
	title = {Class incremental named entity recognition without forgetting},
	volume = {67},
	issn = {0219-1377, 0219-3116},
	url = {https://link.springer.com/10.1007/s10115-024-02220-5},
	doi = {10.1007/s10115-024-02220-5},
	language = {en},
	number = {1},
	urldate = {2025-12-12},
	journal = {Knowl Inf Syst},
	author = {Liu, Ye and Huang, Shaobin and Wei, Chi and Tian, Sicheng and Li, Rongsheng and Yan, Naiyu and Du, Zhijuan},
	month = jan,
	year = {2025},
	pages = {301--324},
	file = {Full Text PDF:files/1753/Liu et al. - 2025 - Class incremental named entity recognition without.pdf:application/pdf},
}

@inproceedings{sekiya_improvements_2022-1,
	title = {Improvements of a {Hybrid} {Syllabus} {Search} {Tool} by {Syllabus}-related {Heuristics}},
	url = {https://ieeexplore.ieee.org/document/9962619},
	doi = {10.1109/FIE56618.2022.9962619},
	abstract = {This Research Full Paper proposes a new method to collect course syllabi. A syllabus is essential information about a course in a university. Students grasp the topics covered by a course through its syllabus, and faculties understand the curriculum offered by the university by a set of syllabi. Thus, a syllabus helps to analyze educational activities. Our previous work proposed a hybrid method that combines Google API as a general keyword search engine and linear support vector machine (SVM) as content-based classification models. We could find more computer science (CS) syllabus pages than using each method alone by employing the hybrid method. This paper extends the hybrid method for finding a directory page with many links to the syllabus pages. We use the hybrid method to collect candidate directory pages and select the true directory pages from the candidates by the three heuristics: (1) Hyperlink-Induced Topic Search (HITS) score. (2) URL pattern, and (3) Content word. (1) HITS score: The relation between directory pages and syllabus pages resembles the relation between the HITS algorithm’s hubs and authorities. We use hub scores to select directory pages. (2) URL pattern: Pages with similar contents and roles share a part of their URLs. We exploit this observation to select syllabus pages. (3) Content word: We expect a syllabus page to include words of the Body of Knowledge (BOK) ‘Computing Science Curricula CS2013,’ released by the ACM and IEEE Computer Society. We use the words extracted from the CS2013 BOK to measure how each candidate syllabus page is related to CS2013. With these three heuristics, we achieved 32\%, the percentage of CS syllabus pages included on candidate pages.},
	urldate = {2025-12-12},
	booktitle = {2022 {IEEE} {Frontiers} in {Education} {Conference} ({FIE})},
	author = {Sekiya, Takayuki and Matsuda, Yoshitatsu and Yamaguchi, Kazunori},
	month = oct,
	year = {2022},
	note = {ISSN: 2377-634X},
	keywords = {Computer science, Computational modeling, Computer Science Curricula, Feature extraction, Heuristic algorithms, HITS algorithm, Keyword search, Linear SVM, Support vector machines, Syllabus Analysis, Uniform resource locators, Web Crawling},
	pages = {1--8},
	file = {Full Text PDF:files/1755/Sekiya et al. - 2022 - Improvements of a Hybrid Syllabus Search Tool by S.pdf:application/pdf},
}

@article{ladas_programming_2023,
	title = {Programming techniques for improving rule readability for rule-based information extraction natural language processing pipelines of unstructured and semi-structured medical texts},
	volume = {29},
	issn = {1460-4582},
	url = {https://doi.org/10.1177/14604582231164696},
	doi = {10.1177/14604582231164696},
	abstract = {BackgroundExtraction of medical terms and their corresponding values from semi-structured and unstructured texts of medical reports can be a time-consuming and error-prone process. Methods of natural language processing (NLP) can help define an extraction pipeline for accomplishing a structured format transformation strategy.ObjectivesIn this paper, we build an NLP pipeline to extract values of the classification of malignant tumors (TNM) from unstructured and semi-structured pathology reports and import them further to a structured data source for a clinical study. Our research interest is not focused on standard performance metrics like precision, recall, and F-measure on the test and validation data. We discuss how with the help of software programming techniques the readability of rule-based (RB) information extraction (IE) pipelines can be improved, and therefore minimize the time to correct or update the rules, and efficiently import them to another programming language.MethodsThe extract rules were manually programmed with training data of TNM classification and tested in two separate pipelines based on design specifications from domain experts and data curators. Firstly we implemented each rule directly in one line for each extraction item. Secondly, we reprogrammed them in a readable fashion through decomposition and intention-revealing names for the variable declaration. To measure the impact of both methods we measure the time for the fine-tuning and programming of the extractions through test data of semi-structured and unstructured texts.ResultsWe analyze the benefits of improving through readability of the writing of rules, through parallel programming with regular expressions (REGEX), and the Apache Uima Ruta language (AURL). The time for correcting the readable rules in AURL and REGEX was significantly reduced. Complicated rules in REGEX are decomposed and intention-revealing declarations were reprogrammed in AURL in 5 min.ConclusionWe discuss the importance of factor readability and how can it be improved when programming RB text IE pipelines. Independent of the features of the programming language and the tools applied, a readable coding strategy can be proven beneficial for future maintenance and offer an interpretable solution for understanding the extraction and for transferring the rules to other domains and NLP pipelines.},
	language = {EN},
	number = {2},
	urldate = {2025-12-12},
	journal = {Health Informatics J},
	author = {Ladas, Nektarios and Borchert, Florian and Franz, Stefan and Rehberg, Alina and Strauch, Natalia and Sommer, Kim Katrin and Marschollek, Michael and Gietzelt, Matthias},
	month = apr,
	year = {2023},
	note = {Publisher: SAGE Publications Ltd},
	pages = {14604582231164696},
	file = {SAGE PDF Full Text:files/1757/Ladas et al. - 2023 - Programming techniques for improving rule readabil.pdf:application/pdf},
}

@article{macan_college_1990,
	title = {College students' time management: {Correlations} with academic performance and stress},
	volume = {82},
	issn = {1939-2176},
	doi = {10.1037/0022-0663.82.4.760},
	number = {4},
	journal = {Journal of Educational Psychology},
	author = {Macan, Therese H. and Shahani, Comila and Dipboye, Robert L. and Phillips, Amanda P.},
	year = {1990},
	pages = {760--768},
}
